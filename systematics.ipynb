{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cabinetry\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "from IPython.display import Image\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "from uncertainties import unumpy\n",
        "\n",
        "np.random.seed(1010)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- all systematic uncertainties can be included in the model with nuisance parameters\n",
        "- defined in the pyhf specification (usually as up/down variatons)\n",
        "- depending on the type of systematic and its correlation, different modifiers can be used\n",
        "- modifiers can be shared over different samples (by having the same name), except for uncorrelated shape\n",
        "- https://pyhf.readthedocs.io/en/v0.7.0/likelihood.html\n",
        "  - uncorrelated shape: *shapesys*\n",
        "  - correlated shape: *histosys*\n",
        "  - normalisation uncertainty: *normsys*\n",
        "  - mc statistical uncertainty: *staterror*\n",
        "  - luminosity: *lumi*\n",
        "  - unconstrained normalisation: *normfactor*\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Image(filename='modifiers.png')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## luminosity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get model from before, with constrained background (normsys)\n",
        "model_dict = cabinetry.workspace.load(\"workspace.json\")  # from json file\n",
        "model, data = cabinetry.model_utils.model_and_data(model_dict)\n",
        "\n",
        "# multiply data by a factor of 2\n",
        "mod_data = [d * 2.0 for i, d in enumerate(data) if (i < model.config.nmaindata)]\n",
        "_ = utils.fit_model(model, mod_data + data[model.config.nmaindata:], goodness_of_fit=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# now we add the luminosity modifier\n",
        "\n",
        "lumi = 2.0  # templates are scaled by this value\n",
        "lumi_uncertainty = 0.02  # 2% uncertainty\n",
        "\n",
        "model_dict = cabinetry.workspace.load(\"workspace.json\")\n",
        "model_dict['measurements'][0]['config']['parameters'].append(\n",
        "    {\"name\": \"lumi\", \"auxdata\": [lumi], \"sigmas\": [lumi_uncertainty * lumi], \"bounds\": [[0.5, 5.0]], \"inits\": [lumi]})\n",
        "model_dict['channels'][0]['samples'][0]['modifiers'].append({'name': 'lumi', 'type': 'lumi', 'data': None})  # signal modifiers\n",
        "model_dict['channels'][0]['samples'][1]['modifiers'].append({'name': 'lumi', 'type': 'lumi', 'data': None})  # background modifiers\n",
        "\n",
        "model, data = cabinetry.model_utils.model_and_data(model_dict)\n",
        "_ = utils.fit_model(model, mod_data + data[model.config.nmaindata:], goodness_of_fit=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## shape modifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_dict = cabinetry.workspace.load(\"workspace.json\")\n",
        "model, data = cabinetry.model_utils.model_and_data(model_dict)\n",
        "bkg_data = model_dict['channels'][0]['samples'][1]['data']\n",
        "\n",
        "# that's our expected deviation on the background template\n",
        "abs_uncrt = np.linspace(-0.1, 0.35, len(bkg_data)) * bkg_data\n",
        "\n",
        "# construct a covariance matrix\n",
        "cov = abs_uncrt[np.newaxis].T * abs_uncrt  # 100% correlated\n",
        "# cov = np.diag(abs_uncrt)**2  # 100% uncorrelated\n",
        "\n",
        "plt.imshow(cov, origin='lower')\n",
        "plt.xlabel('bin')\n",
        "plt.ylabel('bin')\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sample from multivariate gauss using the covariance matrix\n",
        "np.random.seed(80)\n",
        "mod_data = np.random.multivariate_normal(mean=data[:model.config.nmaindata], cov=cov)\n",
        "plt.step(range(len(mod_data)), (mod_data - data[:model.config.nmaindata]) / bkg_data, where='mid')\n",
        "plt.xlabel('bin')\n",
        "plt.ylabel('relative variation')\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fit the modified data with our original model\n",
        "fit_results = utils.fit_model(model, list(mod_data) + data[model.config.nmaindata:], goodness_of_fit=True)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# add correlated shape as background modifier\n",
        "corr_model_dict = cabinetry.workspace.load(\"workspace.json\")\n",
        "corr_model_dict['channels'][0]['samples'][1]['modifiers'].append({\"name\": 'corr_bkg_shape',\n",
        "                                                                  \"type\": \"histosys\",\n",
        "                                                                  \"data\": {\"hi_data\": list(bkg_data + abs_uncrt),\n",
        "                                                                           \"lo_data\": list(bkg_data - abs_uncrt)}\n",
        "                                                                  })\n",
        "corr_model, corr_data = cabinetry.model_utils.model_and_data(corr_model_dict)\n",
        "_ = utils.fit_model(corr_model, list(mod_data) + corr_data[corr_model.config.nmaindata:], goodness_of_fit=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# add uncorrelated shape as background modifier\n",
        "uncorr_model_dict = cabinetry.workspace.load(\"workspace.json\")\n",
        "uncorr_model_dict['channels'][0]['samples'][1]['modifiers'].append({\"name\": 'uncorr_bkg_shape',\n",
        "                                                                    \"type\": \"shapesys\",\n",
        "                                                                    \"data\": list(np.abs(abs_uncrt))})\n",
        "\n",
        "uncorr_model, uncorr_data = cabinetry.model_utils.model_and_data(uncorr_model_dict)\n",
        "_ = utils.fit_model(uncorr_model, list(mod_data) + uncorr_data[uncorr_model.config.nmaindata:], goodness_of_fit=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# toy study with both models\n",
        "# what if we model the correlated shape as uncorrelated and vice versa?\n",
        "\n",
        "n_toys = 50\n",
        "toy_mu = 1.0\n",
        "minos = False\n",
        "results = {}\n",
        "\n",
        "for model, corr_type in zip([corr_model, uncorr_model], ['corr_bkg', 'uncorr_bkg']):\n",
        "\n",
        "    # make toys for all paramters except 'bkg_shape'\n",
        "    toys = utils.make_sys_toys(model, sys_name='bkg_shape', n_toys=n_toys, assumed_value=toy_mu, n1=True)\n",
        "\n",
        "    # sample from multivariate gauss to simulate background shape variation\n",
        "    while True:\n",
        "        toys_actualdata = [np.random.multivariate_normal(mean=mean, cov=cov) for mean in toys[:, :model.config.nmaindata]]\n",
        "        if (np.array(toys_actualdata) < 0).sum() == 0:\n",
        "            break\n",
        "\n",
        "    # replace actualdata in toys with new sampled data\n",
        "    toys[:, :model.config.nmaindata] = toys_actualdata\n",
        "\n",
        "    fails = 0\n",
        "    res = []\n",
        "    for i, toy in tqdm(enumerate(toys), total=n_toys):\n",
        "        try:\n",
        "            # preform the fit\n",
        "            fit_results = cabinetry.fit.fit(model, toy, goodness_of_fit=True, minos=model.config.poi_name if minos else [])\n",
        "\n",
        "            # get some information from the fit results\n",
        "            bestfit = fit_results.bestfit[model.config.poi_index].item()\n",
        "            fit_unc = fit_results.uncertainty[model.config.poi_index].item()\n",
        "            gof = fit_results.goodness_of_fit\n",
        "            nll = fit_results.best_twice_nll\n",
        "\n",
        "            # compute pull\n",
        "            if minos:\n",
        "                minos_unc = fit_results.minos_uncertainty[model.config.poi_name]\n",
        "                minos_unc_sym = np.abs(minos_unc).sum() / 2\n",
        "                pull = (bestfit - toy_mu) / minos_unc_sym\n",
        "            else:\n",
        "                minos_unc = [np.nan, np.nan]\n",
        "                pull = (bestfit - toy_mu) / fit_unc\n",
        "\n",
        "            # print results and append to list\n",
        "            result = [bestfit, fit_unc, minos_unc[0], minos_unc[1], pull, nll, gof]\n",
        "            names = ['mu', 'unc', 'dn', 'up', 'pull', 'nll', 'gof']\n",
        "            print(f'{i+1:>3}' + ' '.join([f'{name:>6}: {res:<7.3f}' for name, res in zip(names, result)]))\n",
        "            res.append(result)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            fails += 1\n",
        "            print(f'optimisation failed already {fails} times :(')\n",
        "\n",
        "    # clean up some failed fits if there are any\n",
        "    results[corr_type] = np.array(res)[~np.isclose(np.array(res)[:, :4], 0).any(1) & ~np.isnan(np.array(res)[:, -1])]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for corr_type, res in results.items():\n",
        "    print(len(res))\n",
        "    utils.fit_pull(np.array(res)[:, 4], show_bins=20, xlabel=f'pull ({corr_type})')\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- it is important to model all systematic variations and their correlation correctly, not easy to test this\n",
        "- we can only test this here because we have the underlying model, this is usually not available\n",
        "- if we sample from our model we already assume that correlations/systematics are correct!\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitting uncertainty on POI by systeamtic source"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "model_dict = cabinetry.workspace.load(\"workspace.json\")\n",
        "model, data = cabinetry.model_utils.model_and_data(model_dict)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "utils.bestfit_toy_valid(model, sys_name='all', n_toys=500)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sys_uncrt = {}\n",
        "sys_names = ['bkg_shape', 'bkg_norm', 'sig_stat_error', 'bkg_stat_error', 'data_stat_error']\n",
        "for sys_name in sys_names:\n",
        "    sys_uncrt[sys_name] = utils.bestfit_toy_valid(model, sys_name=sys_name)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(tabulate(sys_uncrt.items()))\n",
        "print(f'quadrature sum: {unumpy.sqrt(np.sum([uncrt**2 for uncrt in sys_uncrt.values()]))}')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## how to model any arbitrary correlation\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # parabula only for bkg norm, bc of 1 parameter with gaussian constraint ?\n",
        "# toy_results = utils.bestfit_toy_valid(model, sys_name='all', n_toys=500, return_results=True)\n",
        "# toy_results = utils.bestfit_toy_valid(model, sys_name='bkg_norm', n_toys=500, return_results=True)\n",
        "# x_nll = np.array([[toy_result.x[model.config.poi_index], toy_result.fun] for toy_result in toy_results])\n",
        "# plt.plot(*x_nll.T, marker='.', ls='')\n",
        "# plt.hist(x_nll[:, 0], bins=50)\n",
        "# plt.hist(x_nll[:, 1], bins=50)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/usr/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "metadata": {
        "debugger": true
      },
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}